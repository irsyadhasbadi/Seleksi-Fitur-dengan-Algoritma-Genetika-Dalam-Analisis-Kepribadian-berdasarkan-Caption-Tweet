{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a7u1n0pfq664"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 0) Konfigurasi ======\n",
        "MAX_TFIDF_FEATURES = 1000     # target jumlah fitur TF-IDF\n",
        "JUMLAH_FITUR = 1000           # target k untuk Chi-Square (akan disesuaikan otomatis)\n",
        "\n",
        "# ====== 1) Fungsi bantu ======\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def get_text_col(df):\n",
        "    if 'full_text' in df.columns: return 'full_text'\n",
        "    if 'text' in df.columns: return 'text'\n",
        "    raise KeyError(\"Tidak ditemukan kolom teks. Harap sediakan 'full_text' atau 'text'.\")"
      ],
      "metadata": {
        "id": "epvJdtZ81a7T"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 2) Load & prepro TRAIN ======\n",
        "df = pd.read_csv(\"Data_Train.csv\")\n",
        "text_col = get_text_col(df)\n",
        "df['clean_text'] = df[text_col].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "XkPxjBfnrDoB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label dimensi\n",
        "for col in ['IE', 'NS', 'TF', 'JP']:\n",
        "    if col not in df.columns:\n",
        "        raise KeyError(f\"Kolom label '{col}' tidak ditemukan di Data_Train.csv\")\n",
        "\n",
        "y_IE = df['IE'].values\n",
        "y_NS = df['NS'].values\n",
        "y_TF = df['TF'].values\n",
        "y_JP = df['JP'].values\n",
        "\n",
        "# 3 Split indeks\n",
        "train_idx, val_idx = train_test_split(\n",
        "    np.arange(len(df)),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_IE\n",
        ")\n"
      ],
      "metadata": {
        "id": "1cfnlDEGrLvj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 4) TF-IDF: fit di TRAIN saja, transform VAL ======\n",
        "vectorizer = TfidfVectorizer(max_features=MAX_TFIDF_FEATURES)\n",
        "X_train_tfidf = vectorizer.fit_transform(df.loc[train_idx, 'clean_text']).toarray()\n",
        "X_val_tfidf   = vectorizer.transform(df.loc[val_idx,   'clean_text']).toarray()\n",
        "\n",
        "# ====== 5) Binerisasi pakai threshold MEDIAN dari TRAIN ======\n",
        "threshold = np.median(X_train_tfidf, axis=0)\n",
        "X_train = (X_train_tfidf > threshold).astype(int)\n",
        "X_val   = (X_val_tfidf   > threshold).astype(int)\n",
        "\n",
        "# ====== 6) Siapkan label train/val per dimensi ======\n",
        "y_train_IE, y_val_IE = y_IE[train_idx], y_IE[val_idx]\n",
        "y_train_NS, y_val_NS = y_NS[train_idx], y_NS[val_idx]\n",
        "y_train_TF, y_val_TF = y_TF[train_idx], y_TF[val_idx]\n",
        "y_train_JP, y_val_JP = y_JP[train_idx], y_JP[val_idx]\n",
        "\n",
        "labels = {\n",
        "    'IE': (y_train_IE, y_val_IE),\n",
        "    'NS': (y_train_NS, y_val_NS),\n",
        "    'TF': (y_train_TF, y_val_TF),\n",
        "    'JP': (y_train_JP, y_val_JP),\n",
        "}\n",
        "\n",
        "print(f\"Jumlah data training   : {X_train.shape[0]}\")\n",
        "print(f\"Jumlah data validasi   : {X_val.shape[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB3qKMRYrfIy",
        "outputId": "2dbcf090-91ee-4b92-dcde-8f96b31e29c4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data training   : 7480\n",
            "Jumlah data validasi   : 1870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) Load dataTEST\n",
        "df_test = pd.read_csv(\"Data_Test.csv\")\n",
        "text_col_test = get_text_col(df_test)\n",
        "df_test['clean_text'] = df_test[text_col_test].apply(clean_text)\n",
        "\n",
        "for col in ['IE', 'NS', 'TF', 'JP']:\n",
        "    if col not in df_test.columns:\n",
        "        raise KeyError(f\"Kolom label '{col}' tidak ditemukan di Data_Test.csv\")\n",
        "\n",
        "# Transform TF-IDF TEST pakai vectorizer TRAIN, lalu binerisasi pakai threshold TRAIN\n",
        "X_test_tfidf = vectorizer.transform(df_test['clean_text']).toarray()\n",
        "X_test       = (X_test_tfidf > threshold).astype(int)\n",
        "\n",
        "labels_test = {\n",
        "    'IE': df_test['IE'].values,\n",
        "    'NS': df_test['NS'].values,\n",
        "    'TF': df_test['TF'].values,\n",
        "    'JP': df_test['JP'].values,\n",
        "}\n"
      ],
      "metadata": {
        "id": "jDwNXITRr3aE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Training per dimensi ---\n",
        "trained_models = {}\n",
        "trained_selectors = {}\n",
        "\n",
        "n_features = X_train.shape[1]\n",
        "k_eff = min(JUMLAH_FITUR, n_features)\n",
        "print(f\"Jumlah fitur TF-IDF aktual: {n_features} | k efektif Chi-Square: {k_eff}\")\n",
        "\n",
        "for dim, (y_tr, y_va) in labels.items():\n",
        "    print(f\"\\n=== Training Dimensi {dim} ===\")\n",
        "\n",
        "    # Feature selection\n",
        "    selector = SelectKBest(score_func=chi2, k=k_eff)\n",
        "    Xtr_sel = selector.fit_transform(X_train, y_tr)\n",
        "    Xva_sel = selector.transform(X_val)\n",
        "\n",
        "    # Train SVM\n",
        "    clf = SVC(kernel='linear', random_state=42)\n",
        "    clf.fit(Xtr_sel, y_tr)\n",
        "\n",
        "    # Simpan model & selector\n",
        "    trained_models[dim] = clf\n",
        "    trained_selectors[dim] = selector\n",
        "\n",
        "    # Validasi\n",
        "    y_pred_val = clf.predict(Xva_sel)\n",
        "    print(\"Akurasi (Val):\", accuracy_score(y_va, y_pred_val))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olNISgk3sLoO",
        "outputId": "7e44613c-f65b-4e16-b5b8-505038cbccd5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah fitur TF-IDF aktual: 1000 | k efektif Chi-Square: 1000\n",
            "\n",
            "=== Training Dimensi IE ===\n",
            "Akurasi (Val): 0.6550802139037433\n",
            "\n",
            "=== Training Dimensi NS ===\n",
            "Akurasi (Val): 0.5871657754010695\n",
            "\n",
            "=== Training Dimensi TF ===\n",
            "Akurasi (Val): 0.6898395721925134\n",
            "\n",
            "=== Training Dimensi JP ===\n",
            "Akurasi (Val): 0.6149732620320856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Testing per dimensi ---\n",
        "print(\"\\n=== Pengujian dengan Data Test ===\")\n",
        "for dim in labels.keys():\n",
        "    selector = trained_selectors[dim]\n",
        "    clf = trained_models[dim]\n",
        "\n",
        "    Xte_sel = selector.transform(X_test)\n",
        "    y_test_dim = labels_test[dim]\n",
        "\n",
        "    y_pred_test = clf.predict(Xte_sel)\n",
        "\n",
        "    print(f\"\\nDimensi {dim} - Akurasi (Test):\", accuracy_score(y_test_dim, y_pred_test))\n",
        "    print(\"Confusion Matrix (Test):\\n\", confusion_matrix(y_test_dim, y_pred_test))\n",
        "    print(\"Classification Report (Test):\\n\", classification_report(y_test_dim, y_pred_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX3wyqvQyqPI",
        "outputId": "7840a4df-869f-442c-8829-7b7fba59477b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Pengujian dengan Data Test ===\n",
            "\n",
            "Dimensi IE - Akurasi (Test): 0.6417391304347826\n",
            "Confusion Matrix (Test):\n",
            " [[1359  191]\n",
            " [ 633  117]]\n",
            "Classification Report (Test):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           E       0.68      0.88      0.77      1550\n",
            "           I       0.38      0.16      0.22       750\n",
            "\n",
            "    accuracy                           0.64      2300\n",
            "   macro avg       0.53      0.52      0.49      2300\n",
            "weighted avg       0.58      0.64      0.59      2300\n",
            "\n",
            "\n",
            "Dimensi NS - Akurasi (Test): 0.5839130434782609\n",
            "Confusion Matrix (Test):\n",
            " [[999 351]\n",
            " [606 344]]\n",
            "Classification Report (Test):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.62      0.74      0.68      1350\n",
            "           S       0.49      0.36      0.42       950\n",
            "\n",
            "    accuracy                           0.58      2300\n",
            "   macro avg       0.56      0.55      0.55      2300\n",
            "weighted avg       0.57      0.58      0.57      2300\n",
            "\n",
            "\n",
            "Dimensi TF - Akurasi (Test): 0.5921739130434782\n",
            "Confusion Matrix (Test):\n",
            " [[1155  245]\n",
            " [ 693  207]]\n",
            "Classification Report (Test):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           F       0.62      0.82      0.71      1400\n",
            "           T       0.46      0.23      0.31       900\n",
            "\n",
            "    accuracy                           0.59      2300\n",
            "   macro avg       0.54      0.53      0.51      2300\n",
            "weighted avg       0.56      0.59      0.55      2300\n",
            "\n",
            "\n",
            "Dimensi JP - Akurasi (Test): 0.5530434782608695\n",
            "Confusion Matrix (Test):\n",
            " [[368 782]\n",
            " [246 904]]\n",
            "Classification Report (Test):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           J       0.60      0.32      0.42      1150\n",
            "           P       0.54      0.79      0.64      1150\n",
            "\n",
            "    accuracy                           0.55      2300\n",
            "   macro avg       0.57      0.55      0.53      2300\n",
            "weighted avg       0.57      0.55      0.53      2300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3NLw0hH02vIz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}